# 수능 국어 문제 자동 채점 시스템

OpenAI GPT 모델을 활용한 수능 국어 문제 자동 해결 시스템입니다. 다양한 모델과 프롬프트 조합의 성능을 비교 분석하고, 처리 시간까지 측정하여 최적의 설정을 찾는 것을 목표로 합니다.

## 주요 기능

### 🎯 핵심 기능
- **다중 모델 지원**: GPT-4o, GPT-4o-mini 모델 비교
- **다양한 프롬프트 전략**: Zero-shot, Negative prompting, Function calling
- **자동 문제 유형 분류**: AI 기반 문제 유형 자동 판별
- **시간 성능 측정**: 단락별, 문제별 상세 처리 시간 분석
- **종합 성능 평가**: 정확도와 효율성을 모두 고려한 평가

### 📊 분석 기능
- 조합별 정답률 및 점수 비교
- 처리 시간 효율성 분석
- 단락 길이에 따른 성능 패턴 분석
- 비용 대비 성능 분석
- 상황별 최적 조합 추천

## 시스템 요구사항

### 필수 라이브러리
```python
openai >= 1.0.0
pandas
json
re
time
typing
os
datetime
```

### 환경 설정
- Python 3.7+
- OpenAI API 키 (환경변수 `OPENAI_API_KEY` 설정 필요)
- 수능 문제 데이터 JSON 파일

## 설치 및 사용법

### 1. 환경 설정
```bash
pip install openai pandas
export OPENAI_API_KEY="your-openai-api-key"
```

### 2. 데이터 준비
수능 문제 데이터를 다음 형식의 JSON 파일로 준비합니다:
```json
[
  {
    "id": "문제세트ID",
    "paragraph": "지문 내용",
    "type": 0,
    "problems": [
      {
        "question": "문제 내용",
        "choices": ["선택지1", "선택지2", "선택지3", "선택지4", "선택지5"],
        "answer": 정답번호,
        "score": 배점,
        "question_plus": "추가 지문 (선택사항)"
      }
    ]
  }
]
```

### 3. 실행
주피터 노트북에서 셀 단위로 순차 실행하거나, 전체 스크립트를 실행합니다:
```python
python suneung_auto_grading.py
```

## 프롬프트 전략

### 1. Zero-shot
- 기본적인 문제 해결 방식
- 별도의 지시사항 없이 직접적인 문제 해결

### 2. Negative Prompting
- 추측 금지, 확실하지 않은 답 피하기 등의 제약 조건 추가
- 신중한 접근을 통한 정확도 향상 도모

### 3. Function Calling
- 문제 유형별 맞춤형 프롬프트 사용
- 어휘/문법, 내용파악, 추론, 추가지문 문제 등으로 세분화

## 실험 결과 분석

### 성능 지표
- **정답률**: 전체 문제 중 정답 비율
- **획득 점수**: 실제 수능 배점 기준 점수
- **처리 시간**: 문제당 평균 처리 시간
- **효율성 점수**: 정확도와 속도를 종합한 지표

### 시간 분석
- 단락별 처리 시간
- 문제별 처리 시간
- API 호출 시간
- 문제 유형 분류 시간

## 활용 사례

### 교육 분야
- 학생 모의고사 자동 채점
- 문제 유형별 취약점 분석
- 개인 맞춤형 학습 가이드 제공

### 연구 분야
- LLM 성능 벤치마킹
- 프롬프트 엔지니어링 연구
- 교육용 AI 모델 평가

### 실무 적용
- 교육 콘텐츠 품질 검증
- 자동 문제 생성 시스템 평가
- AI 튜터 시스템 성능 측정

## 주의사항

### API 사용량
- OpenAI API 비용이 발생할 수 있습니다
- 실험 전 예상 비용을 계산해보시기 바랍니다
- API 호출 제한을 고려하여 적절한 대기 시간을 설정했습니다

### 데이터 보안
- 수능 문제 데이터의 저작권을 확인해주세요
- API를 통해 전송되는 데이터의 보안을 고려해주세요

## 결과 해석 가이드

### 상황별 권장 조합
1. **최고 정확도 필요**: GPT-4o + Function calling
2. **빠른 처리 필요**: GPT-4o-mini + Zero-shot
3. **균형 잡힌 성능**: GPT-4o-mini + Function calling
4. **비용 효율성**: 성능 차이가 5%p 미만일 경우 GPT-4o-mini 권장

### 성능 지표 해석
- 정답률 80% 이상: 우수한 성능
- 문제당 5초 이하: 실용적인 처리 속도
- 효율성 점수 0.7 이상: 종합적으로 우수한 조합

## 기여 및 개선

### 개선 가능한 부분
- 추가 프롬프트 전략 실험
- 다른 LLM 모델과의 비교
- 문제 유형별 세부 분석 강화
- 실시간 성능 모니터링 기능

### 연락처
프로젝트 관련 문의나 개선 제안은 이슈를 통해 남겨주시기 바랍니다.

## 라이선스
이 프로젝트는 교육 및 연구 목적으로 제작되었습니다. 상업적 사용 시 관련 저작권을 확인해주시기 바랍니다.